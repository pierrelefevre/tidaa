{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./taxi_data/\"\n",
    "yellow_path = \"yellow_taxi/yellow_tripdata_2019-\"\n",
    "yellow_fields = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID']\n",
    "\n",
    "green_path = \"green_taxi/green_tripdata_2019-\"\n",
    "green_fields = ['lpep_pickup_datetime','lpep_dropoff_datetime','PULocationID','DOLocationID']\n",
    "\n",
    "for_hire_path = \"for_hire/fhv_tripdata_2019-\"\n",
    "for_hire_fields = ['pickup_datetime','dropoff_datetime','PULocationID','DOLocationID']\n",
    "\n",
    "high_volume_path = \"high_volume_for_hire/fhvhv_tripdata_2019-\"\n",
    "high_volume_fields = ['pickup_datetime','dropoff_datetime','PULocationID','DOLocationID']\n",
    "\n",
    "headers = ['travel_time',\n",
    "'pickup_time',\n",
    "'OrigLat',\n",
    "'OrigLon',\n",
    "'DestLat',\n",
    "'DestLon',\n",
    "'Distance']\n",
    "\n",
    "\n",
    "\n",
    "train_filename = 'cleaned.csv'\n",
    "\n",
    "test_filename ='test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(data):\n",
    "    print(\"Rows     : \", data.shape[0])\n",
    "    print(\"Columns  : \", data.shape[1])\n",
    "    print(\"\\nFeatures : \\n\", data.columns.tolist())\n",
    "    print(\"\\nMissing values :  \", data.isnull().sum().values.sum())\n",
    "    print(\"\\nUnique values :\\n\", data.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df,fields):\n",
    "    df = df.dropna()\n",
    "    ## Convert to datetime\n",
    "    df.loc[:,fields[0]] = pd.to_datetime(df.loc[:,fields[0]])\n",
    "    df.loc[:,fields[1]] = pd.to_datetime(df.loc[:,fields[1]])\n",
    "\n",
    "    ## Convert to travel time\n",
    "    df.loc[:,'travel_time_diff'] = df[fields[1]] - df[fields[0]]\n",
    "    df = df.rename(columns={fields[0]:'pickup'})\n",
    "    \n",
    "    df = df.drop([fields[1]], axis=1)\n",
    "    \n",
    "    df.loc[:,'travel_time'] = df.loc[:,'travel_time_diff'].dt.total_seconds()\n",
    "    df.loc[:,'travel_time'] = df.loc[:,'travel_time'] / 60\n",
    "    df = df.drop(['travel_time_diff'], axis=1)\n",
    "\n",
    "    ## Convert pickup to time of day\n",
    "    df['pickup_time'] = df['pickup'].dt.hour.astype(int)\n",
    "    df = df.drop(['pickup'], axis=1)\n",
    "\n",
    "    # Chomp all decimals\n",
    "    df.loc[:,'PULocationID'] = df.loc[:,'PULocationID'].astype(int)\n",
    "    df.loc[:,'DOLocationID'] = df.loc[:,'DOLocationID'].astype(int)\n",
    "    df.loc[:,'travel_time'] = df.loc[:,'travel_time'].astype(int)\n",
    "\n",
    "    # remove rows from df that have a longer travel time than the max travel time\n",
    "    MAX_TRAVEL_TIME = 60*5  # 5 hours\n",
    "    df = df[df.loc[:,'travel_time'] < MAX_TRAVEL_TIME]\n",
    "    df = df[df.loc[:,'travel_time'] > 0] \n",
    "\n",
    "    #remove row from df if pulocationid is 264 or 265 as they are unknow locations\n",
    "    df = df[df.loc[:,'PULocationID'] < 264]\n",
    "    df = df[df.loc[:,'DOLocationID'] < 264]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_coordinates(df):\n",
    "    # Convert zone ids to coordinates. Remove any rows that have missing coordinates\n",
    "\n",
    "    lookup = pd.read_csv('taxi_lookup.csv')\n",
    "\n",
    "    df.loc[:,'OrigLat'] = df.loc[:,'PULocationID'].map(lookup.set_index('LocationID')['lat'])\n",
    "    df.loc[:,'OrigLon'] = df.loc[:,'PULocationID'].map(lookup.set_index('LocationID')['long'])\n",
    "    df.loc[:,'DestLat'] = df.loc[:,'DOLocationID'].map(lookup.set_index('LocationID')['lat'])\n",
    "    df.loc[:,'DestLon'] = df.loc[:,'DOLocationID'].map(lookup.set_index('LocationID')['long'])\n",
    "\n",
    "\n",
    "    df['Distance'] = ((((df['DestLon'] - df['OrigLon'] )**2) + ((df['DestLat']-df['OrigLat'])**2) )**0.5)\n",
    "\n",
    "    df = df.drop(['PULocationID', 'DOLocationID'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(df,train_filename,test_filename):\n",
    "    from os.path import exists\n",
    "    test = df.sample(frac=0.0001)\n",
    "    df.drop(test.index)\n",
    "    if(exists(train_filename)):\n",
    "        df.to_csv(train_filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(train_filename, index=False)\n",
    "\n",
    "    if(exists(test_filename)):\n",
    "        test.to_csv(test_filename,mode='a',header=False, index=False)\n",
    "    else:\n",
    "        test.to_csv(test_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean (path, fileEndings ,fields, train_filename,test_filename):\n",
    "    import datetime\n",
    "\n",
    "    last = datetime.datetime.now().replace(microsecond=0)\n",
    "    total = last\n",
    "    for i in fileEndings:\n",
    "        print(\"Reading \" + str(i)  , end='')\n",
    "        df = pd.read_csv(path + str(i) + \".csv\", usecols=fields)\n",
    "        print(\".\", end = '')\n",
    "        df = clean(df,fields)\n",
    "        print(\".\", end = '')\n",
    "        df = convert_to_coordinates(df)\n",
    "        print(\". \" +\" \" + str(len(df.index)) +  \" rows, Saving -> \", end='')\n",
    "        saveData(df,train_filename,test_filename)\n",
    "        print(\"Saved\", end='')\n",
    "        now = datetime.datetime.now().replace(microsecond=0)\n",
    "        print(\" - \" + str(now-last) + \" elapsed - total time elapsed \" + str(now-total))\n",
    "        last = now\n",
    "    print(\"Total time elapsed: \" + str(datetime.datetime.now()-total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1...  7403443 rows, Saving -> Saved - 0:00:53 elapsed - total time elapsed 0:00:53\n",
      "Reading 2...  6854375 rows, Saving -> Saved - 0:00:48 elapsed - total time elapsed 0:01:41\n",
      "Reading 3...  7673438 rows, Saving -> Saved - 0:00:53 elapsed - total time elapsed 0:02:34\n",
      "Reading 4...  7262022 rows, Saving -> Saved - 0:00:51 elapsed - total time elapsed 0:03:25\n",
      "Reading 5...  7390685 rows, Saving -> Saved - 0:00:52 elapsed - total time elapsed 0:04:17\n",
      "Reading 6...  6774429 rows, Saving -> Saved - 0:00:50 elapsed - total time elapsed 0:05:07\n",
      "Reading 7...  6158872 rows, Saving -> Saved - 0:00:48 elapsed - total time elapsed 0:05:55\n",
      "Reading 8...  5922087 rows, Saving -> Saved - 0:00:45 elapsed - total time elapsed 0:06:40\n",
      "Reading 9...  6413960 rows, Saving -> Saved - 0:00:46 elapsed - total time elapsed 0:07:26\n",
      "Reading 10...  7054853 rows, Saving -> Saved - 0:00:51 elapsed - total time elapsed 0:08:17\n",
      "Reading 11...  6726880 rows, Saving -> Saved - 0:00:47 elapsed - total time elapsed 0:09:04\n",
      "Reading 12...  6740736 rows, Saving -> Saved - 0:00:47 elapsed - total time elapsed 0:09:51\n",
      "Total time elapsed: 0:09:51.179259\n"
     ]
    }
   ],
   "source": [
    "dataClean(path+yellow_path, [1,2,3,4,5,6,7,8,9,10,11,12], yellow_fields , train_filename, test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2...  19549750 rows, Saving -> Saved - 0:02:10 elapsed - total time elapsed 0:02:10\n",
      "Reading 3...  23131107 rows, Saving -> Saved - 0:02:33 elapsed - total time elapsed 0:04:43\n",
      "Reading 4...  21051857 rows, Saving -> Saved - 0:02:19 elapsed - total time elapsed 0:07:02\n",
      "Reading 5...  21617898 rows, Saving -> Saved - 0:02:23 elapsed - total time elapsed 0:09:25\n",
      "Reading 6...  20298209 rows, Saving -> Saved - 0:02:13 elapsed - total time elapsed 0:11:38\n",
      "Reading 7...  19642853 rows, Saving -> Saved - 0:02:13 elapsed - total time elapsed 0:13:51\n",
      "Reading 8...  19447929 rows, Saving -> Saved - 0:02:13 elapsed - total time elapsed 0:16:04\n",
      "Reading 9...  19373240 rows, Saving -> Saved - 0:02:13 elapsed - total time elapsed 0:18:17\n",
      "Reading 10...  20434864 rows, Saving -> Saved - 0:02:18 elapsed - total time elapsed 0:20:35\n",
      "Reading 11...  20930180 rows, Saving -> Saved - 0:02:22 elapsed - total time elapsed 0:22:57\n",
      "Reading 12...  21530257 rows, Saving -> Saved - 0:02:26 elapsed - total time elapsed 0:25:23\n",
      "Total time elapsed: 0:25:23.822603\n"
     ]
    }
   ],
   "source": [
    "dataClean(path+high_volume_path, list(range(2,13)),high_volume_fields,train_filename, test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For hire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..  19830183 rows, Saving -> Saved - 0:02:15 elapsed - total time elapsed 0:02:15\n",
      "Reading 2...  175984 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:02:19\n",
      "Reading 3...  100457 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:02:22\n",
      "Reading 4...  225552 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:27\n",
      "Reading 5...  228956 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:32\n",
      "Reading 6...  242454 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:37\n",
      "Reading 7...  257736 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:42\n",
      "Reading 8...  286283 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:47\n",
      "Reading 9...  273952 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:02:51\n",
      "Reading 10...  308690 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:02:56\n",
      "Reading 11...  255725 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:03:00\n",
      "Reading 12...  325958 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:03:05\n",
      "Total time elapsed: 0:03:05.860885\n"
     ]
    }
   ],
   "source": [
    "dataClean(path+for_hire_path, list(range(1,13)), for_hire_fields, train_filename, test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1...  613054 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:00:05\n",
      "Reading 2...  559416 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:00:09\n",
      "Reading 3...  584355 rows, Saving -> Saved - 0:00:05 elapsed - total time elapsed 0:00:14\n",
      "Reading 4...  500092 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:17\n",
      "Reading 5...  491576 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:00:21\n",
      "Reading 6...  458185 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:24\n",
      "Reading 7...  457789 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:00:28\n",
      "Reading 8...  436743 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:31\n",
      "Reading 9...  436456 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:34\n",
      "Reading 10...  463979 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:37\n",
      "Reading 11...  437954 rows, Saving -> Saved - 0:00:03 elapsed - total time elapsed 0:00:40\n",
      "Reading 12...  439452 rows, Saving -> Saved - 0:00:04 elapsed - total time elapsed 0:00:44\n",
      "Total time elapsed: 0:00:44.081862\n"
     ]
    }
   ],
   "source": [
    "dataClean(path+green_path, list(range(1,13)),green_fields,train_filename, test_filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
